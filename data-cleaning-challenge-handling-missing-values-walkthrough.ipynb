{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
    "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
   },
   "source": [
    "## Walkthrough provided by:\n",
    "Tatman, R. (2018, March 30). Data Cleaning challenge: Handling missing values. www.kaggle.com. https://www.kaggle.com/code/rtatman/data-cleaning-challenge-handling-missing-values\n",
    "\n",
    "Here's what we're going to do today:\n",
    "\n",
    "* [Take a first look at the data](#Take-a-first-look-at-the-data)\n",
    "* [See how many missing data points we have](#See-how-many-missing-data-points-we-have)\n",
    "* [Figure out why the data is missing](#Figure-out-why-the-data-is-missing)\n",
    "* [Drop missing values](#Drop-missing-values)\n",
    "* [Filling in missing values](#Filling-in-missing-values)\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
    "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
   },
   "source": [
    "# Take a first look at the data\n",
    "________\n",
    "\n",
    "The first thing we'll need to do is load in the libraries and datasets we'll be using. For today, I'll be using a dataset of events that occured in American Football games for demonstration, and you'll be using a dataset of building permits issued in San Francisco.\n",
    "\n",
    "> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
    "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f"
   },
   "outputs": [],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in all our data\n",
    "nfl_data = pd.read_csv(\"NFL Play by Play 2009-2017 (v4).csv\")\n",
    "sf_permits = pd.read_csv(\"Building_Permits.csv\")\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09b58d03-d34d-497a-b298-12a0ae962e3d",
    "_uuid": "53c84bf86149ac41b237633a1a79d6130d6a2cd4"
   },
   "source": [
    "The first thing I do when I get a new dataset is take a look at some of it. This lets me see that it all read in correctly and get an idea of what's going on with the data. In this case, I'm looking to see if I see any missing values, which will be reprsented with `NaN` or `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# look at a few rows of the nfl_data file. I can see a handful of missing data already!\n",
    "nfl_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "604ac3a4-b1d9-4264-b312-4bbeecdeec00",
    "_uuid": "03ce3b4afe87d98f777172c2c7be066a66a0b237"
   },
   "source": [
    "Yep, it looks like there's some missing values. What about in the sf_permits dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dca377c-95be-40ec-87dc-61a8fca750e2",
    "_uuid": "e389495bb2e5d27ab632d5f3648ca1f912c94706"
   },
   "outputs": [],
   "source": [
    "# your turn! Look at a couple of rows from the sf_permits dataset. Do you notice any missing data?\n",
    "\n",
    "# your code goes here :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33656c2b-a74e-4b76-9af2-d7ecd518577b",
    "_uuid": "400b025f618cc76a39fec2537193f28ba1e49168"
   },
   "source": [
    "# See how many missing data points we have\n",
    "___\n",
    "\n",
    "Ok, now we know that we do have some missing values. Let's see how many we have in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a69ac02d-197b-487b-a38f-2f853d208eed",
    "_uuid": "6dc0e32180c4a3bba003e7886faf126d93affadf"
   },
   "outputs": [],
   "source": [
    "# get the number of missing data points per column\n",
    "missing_values_count = nfl_data.isnull().sum()\n",
    "\n",
    "# look at the # of missing points in the first ten columns\n",
    "missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84455c7e-6c63-4e08-a7b4-7520a61072f9",
    "_uuid": "054ba8782a7b0555336eddb90c985fb638beac4d"
   },
   "source": [
    "That seems like a lot! It might be helpful to see what percentage of the values in our dataset were missing to give us a better sense of the scale of this problem:\n",
    "\n",
    "- `nfl_data.shape`: This returns a tuple with the number of rows and columns in the nfl_data DataFrame.\n",
    "\n",
    "- `np.product(nfl_data.shape)`: Multiplies the number of rows and columns to calculate the total number of cells in the DataFrame.\n",
    "\n",
    "- `missing_values_count`: This variable likely contains the count of missing values for each column in the dataset (possibly calculated with `nfl_data.isnull().sum())`.\n",
    "\n",
    "- .`sum()`: Sums the missing values across all columns, resulting in the total number of missing values in the DataFrame.\n",
    "\n",
    "- `(total_missing / total_cells) * 100`: Calculates the percentage of the dataset that has missing values by dividing the number of missing values by the total number of cells and then multiplying by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb77dd56-192e-48be-8181-2082985dd5a2",
    "_uuid": "d6e65ba197893f29d9dce0b0cd1c75017b60db09"
   },
   "outputs": [],
   "source": [
    "# how many total missing values do we have?\n",
    "total_cells = np.product(nfl_data.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "(total_missing/total_cells) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31daa324-9215-4930-985c-01dee717b6b8",
    "_uuid": "3331fa42efa16f3db2e8e196411f351c5f8309f5"
   },
   "source": [
    "Wow, almost a quarter of the cells in this dataset are empty! In the next step, we're going to take a closer look at some of the columns with missing values and try to figure out what might be going on with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f20a9474-41ee-4ecd-a2f4-1ab147fc8655",
    "_uuid": "64487760aa1afaaa8b8a4d1f95206773759db101"
   },
   "outputs": [],
   "source": [
    "# your turn! Find out what percent of the sf_permits dataset is missing\n",
    "\n",
    "# get the number of missing data points per column\n",
    "\n",
    "# look at the # of missing points in the first ten columns\n",
    "\n",
    "# how many total missing values do we have?\n",
    "\n",
    "# percent of data that is missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "62b9f021-5b80-43e2-bf60-8e0d5e22d572",
    "_uuid": "032a618abb98a28e60ab84376cf21402178f995d"
   },
   "source": [
    "# Figure out why the data is missing\n",
    "____\n",
    " \n",
    "This is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to use your intution to figure out why the value is missing. One of the most important question you can ask yourself to help figure this out is this:\n",
    "\n",
    "> **Is this value missing becuase it wasn't recorded or becuase it dosen't exist?**\n",
    "\n",
    "If a value is missing becuase it doens't exist (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it might be. These values you probalby do want to keep as NaN. On the other hand, if a value is missing becuase it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row. (This is called \"imputation\" and we'll learn how to do it next! :)\n",
    "\n",
    "Let's work through an example. Looking at the number of missing values in the nfl_data dataframe, I notice that the column `TimesSec` has a lot of missing values in it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77739e82-8d32-4374-84bf-a924b6065168",
    "_uuid": "b65aea6046964806e44422c057bce8bd7f8e59d5"
   },
   "outputs": [],
   "source": [
    "# look at the # of missing points in the first ten columns\n",
    "missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b17f4c9-dcab-4857-82f9-a2534e804c91",
    "_uuid": "5cff158285ab37a89b80dcc35d5c690cdb42d3a4"
   },
   "source": [
    "By looking at [the documentation](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016), I can see that this column has information on the number of seconds left in the game when the play was made. This means that these values are probably missing because they were not recorded, rather than because they don't exist. So, it would make sense for us to try and guess what they should be rather than just leaving them as NA's.\n",
    "\n",
    "On the other hand, there are other fields, like `PenalizedTeam` that also have lot of missing fields. In this case, though, the field is missing because if there was no penalty then it doesn't make sense to say *which* team was penalized. For this column, it would make more sense to either leave it empty or to add a third value like \"neither\" and use that to replace the NA's.\n",
    "\n",
    "> **Tip:** This is a great place to read over the dataset documentation if you haven't already! If you're working with a dataset that you've gotten from another person, you can also try reaching out to them to get more information.\n",
    "\n",
    "If you're doing very careful data analysis, this is the point at which you'd look at each column individually to figure out the best strategy for filling those missing values. For the rest of this notebook, we'll cover some \"quick and dirty\" techniques that can help you with missing values but will probably also end up removing some useful information or adding some noise to your data.\n",
    "\n",
    "## Your turn!\n",
    "\n",
    "* Look at the columns `Street Number Suffix` and `Zipcode` from the `sf_permits` datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the # of missing points in the first ten columns of sf_permits\n",
    "sf_missing_values_count[0:44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea022b62-6419-47e7-973e-c3e707e2795f",
    "_uuid": "3f72f46f2464c7cd12f5eb2a752746ce1cd0b5a7"
   },
   "source": [
    "# Drop missing values\n",
    "___\n",
    "\n",
    "If you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I don't generally recommend this approch for important projects! It's usually worth it to take the time to go through your data and really look at all the columns with missing values one-by-one to really get to know your dataset.)  \n",
    "\n",
    "If you're sure you want to drop rows with missing values, pandas does have a handy function, `dropna()` to help you do this. Let's try it out on our NFL dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ad0ac9a2-2854-4bb7-8886-8eee7fad8756",
    "_uuid": "ad8ef7825ba9bce3472a47d7c5242a4522f14065"
   },
   "outputs": [],
   "source": [
    "# remove all the rows that contain a missing value\n",
    "nfl_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97709ad4-f7b8-4cd0-8911-56e14db904ae",
    "_uuid": "87c569672854fe23e1ee9376ef3115ba4712cbf5"
   },
   "outputs": [],
   "source": [
    "# remove all columns with at least one missing value\n",
    "columns_with_na_dropped = nfl_data.dropna(axis=1)\n",
    "columns_with_na_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e51b19b-c44d-4487-8417-725d2b911739",
    "_uuid": "e60a092d2799851aa725eadf28b197022a6b127f"
   },
   "outputs": [],
   "source": [
    "# just how much data did we lose?\n",
    "print(\"Columns in original dataset: %d \\n\" % nfl_data.shape[1])\n",
    "print(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e0545655-3d37-448b-ae56-2c7707cd805d",
    "_uuid": "33eb849e076d2a4d0c409f58d78b5f303879b1b3"
   },
   "source": [
    "## What Happened?\n",
    "Oh dear, it looks like that's removed all our data! ðŸ˜± This is because every row in our dataset had at least one missing value. We might have better luck removing all the *columns* that have at least one missing value instead.\n",
    "\n",
    "## What had happened was... (code explanation):\n",
    "- `nfl_data.dropna()`: This line removes any row in the DataFrame nfl_data that contains at least one missing value.\n",
    "- By default, `dropna()` operates along `axis=0` (rows), meaning if a row has any NaN (missing) values, it will be dropped.\n",
    "- Important: This does not modify `nfl_data` in place unless you add `inplace=True`. Without `inplace=True`, the code simply returns a new DataFrame with the rows removed.\n",
    "- `nfl_data.dropna(axis=1)`: This line removes any column that contains at least one missing value. Setting `axis=1` specifies that the operation should be applied to columns instead of rows.\n",
    "- The result is stored in `columns_with_na_dropped`, which is a new DataFrame with all columns containing missing values removed.\n",
    "- We've lost quite a bit of data, but at this point we have successfully removed all the `NaN`'s from our data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0fe94654-7dad-4e8d-bbbb-e65e2bb2f767",
    "_uuid": "8207912f74712835283f7e1b30dad0471ee2e1fc"
   },
   "outputs": [],
   "source": [
    "# Your turn! Try removing all the rows from the sf_permits dataset that contain missing values. How many are left?\n",
    "# remove all the rows that contain a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ec643e1-abba-4683-b794-a1924e657501",
    "_uuid": "f804c0448b18b6d411ddf8452d15abba8292fffa"
   },
   "outputs": [],
   "source": [
    "# Now try removing all the columns with empty values. Now how much of your data is left?\n",
    "# remove all columns with at least one missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1dbe153d-7b30-4ad8-80ad-a4c7fb53928e",
    "_uuid": "eb1ef8d47d9ebed77c3d21eca24708708ed4d45f"
   },
   "source": [
    "# Filling in missing values automatically\n",
    "_____\n",
    "\n",
    "Another option is to try and fill in the missing values. For this next bit, I'm getting a small sub-section of the NFL data so that it will print well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76fd83fb-a6d9-4c03-8c94-a111ee529881",
    "_uuid": "e0944282c73a63513d5345689ddd6a9da0fc8547"
   },
   "outputs": [],
   "source": [
    "# get a small subset of the NFL dataset\n",
    "subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\n",
    "subset_nfl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "527c8703-4b29-459d-af7d-5505da36016b",
    "_uuid": "f8cfe916904af3265d8ecc4f791f9f62e34ff458"
   },
   "source": [
    "### Code Explanation: \n",
    "1. Column Selection (nfl_data.loc[:, 'EPA':'Season']):\n",
    "\n",
    "    - `nfl_data.loc[:, 'EPA':'Season']`: This uses `.loc[]` to select a range of columns from 'EPA' to 'Season'.\n",
    "    - The `:` before 'EPA' specifies that all rows should be included, and `'EPA':'Season'` specifies a range of columns, selecting from 'EPA' up to and including 'Season'.\n",
    "2. Row Selection (`head()`):\n",
    "    - `.head()`: This selects the first 5 rows of the DataFrame.\n",
    "3. Storing the Subset:\n",
    "    - The result, which is a small subset of `nfl_data` (the first 5 rows and columns from 'EPA' to 'Season'), is assigned to the variable `subset_nfl_data`.\n",
    "\n",
    "Final Output\n",
    "    - `subset_nfl_data` will contain a subset of `nfl_data`, limited to the first 5 rows and columns ranging from 'EPA' to 'Season'.\n",
    "    \n",
    "We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, I'm saying that I would like to replace all the `NaN` values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c01ed989-8901-43c8-afa3-6ca36605dfb5",
    "_uuid": "77eac530ce398b8c13eb7886f86bce48fd997f34"
   },
   "outputs": [],
   "source": [
    "# replace all NA's with 0\n",
    "subset_nfl_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1103b725-c823-4f40-9bda-e97997856339",
    "_uuid": "bec603202c6bfaae7a49b4a4042f37019ad1d801"
   },
   "source": [
    "I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90ddac9b-ee20-492e-b437-0519c97ca317",
    "_uuid": "afba99aa7897539e9a0af77dce03daab94d0ca68"
   },
   "outputs": [],
   "source": [
    "# replace all NA's the value that comes directly after it in the same column, \n",
    "# then replace all the reamining na's with 0\n",
    "subset_nfl_data.fillna(method = 'bfill', axis=0).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "980e5d67-7e9c-41a3-b17e-51d87e9da9cf",
    "_uuid": "1f8ac8b52f2933612e315f06a53185e164e6c5bc"
   },
   "source": [
    "Filling in missing values is also known as \"imputation\", and you can find more exercises on it [in this lesson, also linked under the \"More practice!\" section](https://www.kaggle.com/dansbecker/handling-missing-values). \n",
    "\n",
    "First, however, why don't you try replacing some of the missing values in the sf_permit dataset? Let's identify a subset where we can make some assumptions.\n",
    "\n",
    "How about the columns from `Plansets` to `Proposed Construction Type Description`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da426397-7e17-40ce-a0d4-ca6d39e47498",
    "_uuid": "f7d403c19eaf31ee0a4e04b9e1119eda96a9f95c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# get a small subset of the sf_permits dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace all NA's with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace all NA's with the value that two cells to the left, \n",
    "# then replace all the reamining na's with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "# And that's it for today! \n",
    "\n",
    "\n",
    "## More practice!\n",
    "___\n",
    "\n",
    "If you're looking for more practice handling missing values, check out `Data Cleaning Challenge: Handling Missing Values`: https://www.kaggle.com/code/rtatman/data-cleaning-challenge-handling-missing-values\n",
    "\n",
    "## Session 2 Exercise: Data Analysis and Visualization with NumPy, pandas, and Matplotlib\n",
    "\n",
    "In this exercise, you will clean and analyze a dataset using NumPy, pandas, and matplotlib. This will allow you to:\n",
    "- Perform some data cleaning on the dataset.\n",
    "- Perform numerical operations with NumPy.\n",
    "- Load, explore, and filter data using pandas.\n",
    "- Visualize data trends with matplotlib.\n",
    "\n",
    "The dataset provided is `city_temperature_with_nan.csv` with the following columns:\n",
    "- **City**: Name of the city.\n",
    "- **Date**: Date of the recorded temperature (YYYY-MM-DD).\n",
    "- **Temperature**: Recorded temperature in degrees Celsius (some missing values).\n",
    "- **Rainfall (mm)**: Recorded rainfall in millimeters (some missing values).\n",
    "- **Time Zone**: Time zone city is located.\n",
    "\n",
    "### Submission Instructions:\n",
    "1. Rename your notebook in the following format: lastname_firstname.ipynb\n",
    "2. Download your notebook from the dashboard to your local computer.\n",
    "3. Email your notebook to egarza@tacc.utexas.edu, use subject line: ACSC Session 2 Deliverable\n",
    "\n",
    "### Deadline to Submit\n",
    "- If you don't plan to attend the training session then you deadline is 10:00p CT, 9:00p MT, 8:00p PT, 7:00p AKT, 5:00p HT Wednesday (10/30/24).\n",
    "- For all others you can submit by 5:00p CT, 4:00p MT, 3:00p PT, 2:00p AKT, 12:00p HT Monday (11/04/24)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
